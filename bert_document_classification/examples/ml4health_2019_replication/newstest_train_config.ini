model_storage_directory: ./results_newstest_single_gpu_lstm_batch_size10
batch_size: 10
epochs:1000
evaluation_interval: 10
checkpoint_interval: 250
;use_tensorboard

bert_model_path: bert-base-uncased

#clinicalBERT/pretrained_bert_tf/biobert_pretrain_output_all_notes_150000

#You need to replace this with a path to clinicalBert weights
#Find it here: https://github.com/EmilyAlsentzer/clinicalBERT
#bert_model_path: /export/b18/elliot/pretrained_bert_tf/biobert_pretrain_output_all_notes_150000

labels: alt.atheism, talk.religion.misc, comp.graphics, sci.space
architecture: DocumentBertLSTM
freeze_bert: True
bert_batch_size: 7

device cuda:1
cuda
learning_rate: 6e-5
weight_decay: 0

